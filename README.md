# TF_QuantSimul
This repo contains unofficial implementations of following DL model quantization methods.

- QuantSimul.py is implementation of Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (Jacob et al, 2017)

- MBQuant.py is implementation of Distribution-Aware Adaptive Multi-Bit Quantization (Zhao et al, 2021)

The codes are meant to simulate the effects of quantization methods, not actually quantize models to mixed precision models. 

Codes might be 'messy' due to the fact that the implementation is meant to satisfy personal curiosity and not publicly accessible.
