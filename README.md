# TF_QuantSimul
This repo contains unofficial implementations of following DL model quantization methods:

- QuantSimul.py is an implementation of [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (Jacob et al, 2017)](https://arxiv.org/abs/1712.05877)

- MBQuant.py is an implementation of [Distribution-Aware Adaptive Multi-Bit Quantization (Zhao et al, 2021)](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Distribution-Aware_Adaptive_Multi-Bit_Quantization_CVPR_2021_paper.pdf)

The codes are meant to simulate the effects of quantization methods, rather than actually quantize models to mixed precision models. 

Codes might be 'messy' due to the fact that the implementations are meant to satisfy personal curiosity and not publicly accessible.
