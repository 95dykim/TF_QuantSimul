{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f5a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import MBQuantSimul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f700fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicBlock_MBQuantSimul(x, channel_size, name, strides=1, kernel_init=\"glorot_uniform\", kernel_reg = None, tau=1.0):\n",
    "    x_1 = x\n",
    "    x_2 = x\n",
    "    \n",
    "    if strides != 1:\n",
    "        #option_a\n",
    "        x_2 = tf.keras.layers.MaxPool2D(1, strides=strides, padding=\"same\", name=name+\"_sc_maxpool\"  )( tf.pad(x_2, ((0,0), (0,0), (0,0), (0, channel_size-x_2.shape[-1])), name=name+\"_sc_optionA\") )\n",
    "        #option_b\n",
    "        #x_2 = tf.keras.layers.Conv2D(channel_size, 1, strides=strides, padding='same', use_bias=False, name=name+\"_sc_conv\", kernel_initializer=INIT)(x_2)\n",
    "        #x_2 = tf.keras.layers.BatchNormalization(name=name+\"_sc_bn\")(x_2)\n",
    "\n",
    "    x_1 = MBQuantSimul.MBQuantSimulConv2D(channel_size, 3, tau=tau, strides=strides, padding=\"same\", use_bias=False, name=name+\"_conv1\", kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization(name=name+\"_bn1\")(x_1)\n",
    "    x_1 = tf.keras.layers.Activation('relu', name=name+\"_act1\")(x_1)\n",
    "    x_1 = MBQuantSimul.MBQuantActivation(tau=tau, name=name+\"_act1_quantized\")(x_1)\n",
    "    \n",
    "    x_1 = MBQuantSimul.MBQuantSimulConv2D(channel_size, 3, tau=tau, strides=1, padding=\"same\", use_bias=False, name=name+\"_conv2\", kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization(name=name+\"_bn2\")(x_1)\n",
    "    \n",
    "    x = tf.keras.layers.Add(name=name+\"_add\")([x_1, x_2])\n",
    "    x = tf.keras.layers.Activation('relu', name=name+\"_act2\")(x)\n",
    "    x = MBQuantSimul.MBQuantActivation(tau=tau, name=name+\"_act2_quantized\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def ResNet20_MBQuantSimul(input_shape=(32,32,3), classes=10, channel_sizes=16, kernel_init=\"glorot_uniform\", kernel_reg=tf.keras.regularizers.L2(1e-4)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    #pre\n",
    "    x = MBQuantSimul.MBQuantSimulConv2D(channel_sizes, 3, tau=1.0, qconfig=\"distribution_aware\", strides=1, padding=\"same\", use_bias=False, name=\"pre_conv\", kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=\"pre_bn\")(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\",name=\"pre_act\")(x)\n",
    "    x = MBQuantSimul.MBQuantActivation(tau=25.0, name=\"pre_act_quantized\")(x)\n",
    "\n",
    "    #blocks_1\n",
    "    x = BasicBlock_MBQuantSimul(x, channel_sizes, \"blocks_1_1\", strides=1, tau=1.0 )\n",
    "    for i in range(1,3):\n",
    "        x = BasicBlock_MBQuantSimul(x, channel_sizes, \"blocks_1_\"+str(i+1), strides=1, tau=1.0)\n",
    "\n",
    "    #blocks_2\n",
    "    x = BasicBlock_MBQuantSimul(x, channel_sizes*2, \"blocks_2_1\", strides=2, tau=1.0)\n",
    "    for i in range(1,3):\n",
    "        x = BasicBlock_MBQuantSimul(x, channel_sizes*2, \"blocks_2_\"+str(i+1), strides=1, tau=1.0)\n",
    "\n",
    "    #blocks_3\n",
    "    x = BasicBlock_MBQuantSimul(x, channel_sizes*4, \"blocks_3_1\", strides=2, tau=1.0)\n",
    "    for i in range(1,3):\n",
    "        x = BasicBlock_MBQuantSimul(x, channel_sizes*4, \"blocks_3_\"+str(i+1), strides=1, tau=1.0)\n",
    "    \n",
    "    #pred\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"pred_gap\")(x)\n",
    "    x = MBQuantSimul.MBQuantDense(classes, name=\"pred_dense\", tau=1.0, qconfig=\"distribution_aware\", kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(x) #BIAS REGULARIZER X\n",
    "    #x = tf.keras.layers.Dense(classes, name=\"pred_dense\", kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(x) #BIAS REGULARIZER X\n",
    "    x = tf.keras.layers.Activation(\"softmax\", name=\"pred_out\")(x)\n",
    "    outputs = MBQuantSimul.MBQuantActivation(tau=1.0, name=\"pred_out_quantized\")(x)\n",
    "    \n",
    "    return MBQuantSimul.MBQuantModel(inputs=inputs, outputs=outputs, name=\"ResNet20\")\n",
    "    #return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"ResNet20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5173d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)# tf.squeeze( tf.one_hot( y_train, y_train.max()+1 ) )\n",
    "y_test = tf.keras.utils.to_categorical(y_test) #tf.squeeze( tf.one_hot( y_test, y_test.max()+1 ) )\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "x_mean = np.mean(x_train, axis=(0,1,2), keepdims=True)\n",
    "x_std = np.std(x_train, axis=(0,1,2), keepdims=True)\n",
    "\n",
    "x_train = (x_train - x_mean)/x_std\n",
    "x_test = (x_test - x_mean)/x_std\n",
    "\n",
    "#x_train = tf.cast(x_train, tf.float32)\n",
    "#x_test = tf.cast(x_test, tf.float32)\n",
    "#y_train = tf.cast(y_train, tf.float32)\n",
    "#y_test = tf.cast(y_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad6cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_200(epoch, lr):\n",
    "    if epoch <60:\n",
    "        return 0.1\n",
    "    elif epoch <120:\n",
    "        return 0.02\n",
    "    elif epoch <160:\n",
    "        return 0.004\n",
    "    else:\n",
    "        return 0.0008\n",
    "LR_Scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89d227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = \"MBQuant_ResNet20_CIFAR10\"\n",
    "checkpoint_filepath = './' + savename + '/checkpoint_scratch-{epoch}'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5383de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet20_MBQuantSimul()\n",
    "model.accumulate_grads = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92490c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "391/391 [==============================] - 46s 91ms/step - loss: 7.7088 - accuracy: 0.2625 - val_loss: 9.6621 - val_accuracy: 0.3050 - lr: 0.1000\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 35s 88ms/step - loss: 10.1473 - accuracy: 0.3020 - val_loss: 11.5403 - val_accuracy: 0.2257 - lr: 0.1000\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 34s 87ms/step - loss: 10.1585 - accuracy: 0.3192 - val_loss: 10.5262 - val_accuracy: 0.3180 - lr: 0.1000\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 32s 83ms/step - loss: 10.1528 - accuracy: 0.3264 - val_loss: 11.4463 - val_accuracy: 0.2670 - lr: 0.1000\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 9.9882 - accuracy: 0.3382 - val_loss: 11.9600 - val_accuracy: 0.2401 - lr: 0.1000\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.8931 - accuracy: 0.3511 - val_loss: 10.5594 - val_accuracy: 0.3268 - lr: 0.1000\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 35s 88ms/step - loss: 9.7348 - accuracy: 0.3613 - val_loss: 9.8807 - val_accuracy: 0.3616 - lr: 0.1000\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.6725 - accuracy: 0.3676 - val_loss: 9.8983 - val_accuracy: 0.3577 - lr: 0.1000\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 9.6728 - accuracy: 0.3715 - val_loss: nan - val_accuracy: 0.3795 - lr: 0.1000\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 33s 85ms/step - loss: 9.5403 - accuracy: 0.3812 - val_loss: 9.9807 - val_accuracy: 0.3651 - lr: 0.1000\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 9.4607 - accuracy: 0.3886 - val_loss: 9.4839 - val_accuracy: 0.3984 - lr: 0.1000\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 9.3885 - accuracy: 0.3944 - val_loss: 9.2975 - val_accuracy: 0.4063 - lr: 0.1000\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.2931 - accuracy: 0.4018 - val_loss: 9.2230 - val_accuracy: 0.4181 - lr: 0.1000\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 33s 85ms/step - loss: 9.2287 - accuracy: 0.4060 - val_loss: 9.4430 - val_accuracy: 0.4005 - lr: 0.1000\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.2063 - accuracy: 0.4074 - val_loss: 9.5796 - val_accuracy: 0.3967 - lr: 0.1000\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.1808 - accuracy: 0.4105 - val_loss: 9.1536 - val_accuracy: 0.4195 - lr: 0.1000\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 9.1359 - accuracy: 0.4140 - val_loss: 9.8305 - val_accuracy: 0.3774 - lr: 0.1000\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 35s 90ms/step - loss: nan - accuracy: 0.3194 - val_loss: nan - val_accuracy: 0.1000 - lr: 0.1000\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 35s 89ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000 - lr: 0.1000\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1000"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.SGD(0.1, momentum=0.9, nesterov=True)\n",
    "loss_f = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=optim, loss=loss_f, metrics=['accuracy'])\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=128), validation_data=(x_test, y_test), epochs=200, callbacks=[model_checkpoint_callback, LR_Scheduler])\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.to_csv('MBQuantSimul_ResNet20_CIFAR10.csv'.format(savename), index=False)\n",
    "\n",
    "#pd.read_csv(\"BASELINE_ResNet20_CIFAR10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91476e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd763d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
